# Productionâ€‘Grade AI App (FastAPI â€¢ scikitâ€‘learn â€¢ Docker)

**Kurzfassung:**
Eine kleine, saubere KIâ€‘Anwendung von 0 â†’ produktionsreif: Daten vorbereiten, Modell trainieren (scikitâ€‘learn), Ã¼ber eine FastAPI bereitstellen, mit Tests, Logging, `.env`â€‘Konfiguration und Dockerâ€‘Image. Ideal zum Vorzeigen fÃ¼r Arbeitgeber (Codeâ€‘QualitÃ¤t, Struktur, DevOpsâ€‘Basics).

---

## ðŸ”¥ Highlights (fÃ¼r Leser & Arbeitgeber)

* **Klare Projektstruktur:** Trennung von API (`src/app`) und MLâ€‘Code (`src/ml`).
* **Productionâ€‘Basics:** Healthâ€‘Check, Eingabeâ€‘Validierung (Pydantic), Logging, `.env`â€‘Konfiguration.
* **QualitÃ¤t:** Pytestâ€‘Tests (z.â€¯B. `/health`, `/predict`).
* **PortabilitÃ¤t:** Dockerfile, lÃ¤uft lokal & bei Hostern (Render/Railway) â†’ `${PORT}` wird unterstÃ¼tzt.
* **Nachvollziehbarkeit:** Minimaler, gut kommentierter Code â€“ leicht erweiterbar.

---

## ðŸ§­ Projektstruktur

```text
.
â”œâ”€ .dockerignore
â”œâ”€ .gitignore
â”œâ”€ .env.example
â”œâ”€ Dockerfile
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ scripts/
â”‚  â””â”€ run_dev.ps1
â””â”€ src/
   â”œâ”€ app/
   â”‚  â”œâ”€ __init__.py
   â”‚  â””â”€ main.py          # FastAPI: /health, /predict, Logging, .env
   â”œâ”€ ml/
   â”‚  â”œâ”€ __init__.py
   â”‚  â”œâ”€ data_prep.py     # (Beispiel) Daten laden/teilen
   â”‚  â””â”€ train.py         # Modell trainieren â†’ model.joblib
   â””â”€ tests/
      â”œâ”€ test_health.py
      â””â”€ test_predict.py
```

---

## ðŸš€ Schnellstart (lokal)

**Voraussetzungen:** Python 3.10+, pip, (optional) Docker.

```powershell
# 1) Repository klonen
# git clone <dein-repo>
cd <dein-repo>

# 2) Virtuelle Umgebung & Pakete
python -m venv .venv
.venv\Scripts\Activate
pip install -r requirements.txt

# 3) (Optional) Daten vorbereiten
# python src/ml/data_prep.py          # erzeugt train.csv/test.csv
# # oder in Python:
# # from src.ml import data_prep
# # data_prep.run()

# 4) Modell trainieren
python src/ml/train.py               # erzeugt model.joblib
# # oder in Python:
# # from src.ml import train
# # train.run()

# 5) API starten (Entwicklung)
uvicorn src.app.main:app --reload --port 8000
# â†’ http://127.0.0.1:8000/health
```

**Gesundheitscheck:**

```text
GET /health  â†’  {"status":"ok","model_loaded":true,"error":null}
```

---

## ðŸ“¡ API â€“ Endpunkte

### `GET /health`

* **Zweck:** LÃ¤uft der Dienst? Ist das Modell geladen?
* **Antwort (Beispiel):**

  ```json
  { "status": "ok", "model_loaded": true, "error": null }
  ```

### `POST /predict`

* **Body (Beispiel):**

  ```json
  { "feature1": 1.2, "feature2": 3.4 }
  ```
* **Antwort (Beispiel):**

  ```json
  { "prediction": 1 }
  ```
* **Hinweis:** Passe die Felder (`feature1`, `feature2`, â€¦) an **deine Trainingsspalten** an. Namen/Typen mÃ¼ssen 1:1 zu `train.py` passen.

**Schnelltest (PowerShell/curl):**

```powershell
curl -X POST "http://127.0.0.1:8000/predict" `
  -H "Content-Type: application/json" `
  -d "{""feature1"": 1.2, ""feature2"": 3.4}"
```

---

## âš™ï¸ Konfiguration (.env)

Beispiel: `.env.example`

```ini
APP_PORT=8000
ENV=development
LOG_LEVEL=INFO
MODEL_PATH=model.joblib
```

> Kopiere zu `.env` und passe nach Bedarf an. **Hinweis:** `.env` wird nicht eingecheckt.

---

## ðŸ§ª Tests

```powershell
pip install pytest
pytest -q
```

* `test_health.py`: Erwartet HTTP 200 und `{ "status": "ok" }`.
* `test_predict.py`: Erwartet 200 + `prediction` (wenn `model.joblib` existiert), sonst 503.

---

## ðŸ“œ Logging

* Konfiguriert via `logging.basicConfig` und `LOG_LEVEL` (z.â€¯B. `DEBUG`, `INFO`).
* Beispielâ€‘Logereignisse: Appâ€‘Start, Modell geladen/nicht gefunden, Anfragen an `/predict`, Fehler mit Stacktrace.

---

## ðŸ“¦ Docker

**Einfaches Image bauen & starten:**

```powershell
docker build -t ai-app:latest .
docker run --rm -p 8000:8000 --name ai-app ai-app:latest
# â†’ http://127.0.0.1:8000/health
```

**Dockerfile (Startbefehl mit Hostâ€‘Port):**

```dockerfile
CMD ["sh", "-c", "uvicorn src.app.main:app --host 0.0.0.0 --port ${PORT:-8000}"]
```

> Hoster Ã¼bergeben `PORT` (z.â€¯B. 10000). Lokal bleibt 8000 Standard.

---

## â˜ï¸ Deployment (kurz)

* **Render/Railway**: Neues Webâ€‘Service erstellen â†’ Repo verbinden â†’ Docker verwenden â†’ `HealthCheck: /health` â†’ Envâ€‘Variablen setzen (`MODEL_PATH`, `LOG_LEVEL`, â€¦) â†’ Deploy.
* **Wichtig:** Achte darauf, dass `model.joblib` im Image landet (nicht von `.dockerignore` ausgeschlossen).

---

## ðŸ”§ Technischer Stack

* **Backend:** FastAPI, Uvicorn
* **ML:** scikitâ€‘learn, pandas, joblib
* **QualitÃ¤t:** pytest, Pydantic (Validierung)
* **Konfig:** pythonâ€‘dotenv (`.env`)
* **Container:** Docker (Multiâ€‘Stage optional)

---

## ðŸ§± Designâ€‘Entscheidungen (kurz)

* **Trennung von Belangen:** API â‰  MLâ€‘Training â†’ klare Verantwortlichkeiten.
* **Validierung am Rand:** Pydanticâ€Modelle schÃ¼tzen das Modell vor fehlerhaften Eingaben.
* **â€žFail fastâ€œ:** Startup prÃ¼ft Modellpfad; `/health` zeigt Diagnose.
* **12â€‘Factorâ€‘Style:** Config via Env; keine Secrets im Code/Repo.

---

## ðŸ—ºï¸ Roadmap (Ideen)

* Mehr Features/Eingaben + Modellâ€‘Versionierung (`MODEL_VERSION`).
* Metriken/Monitoring (z.â€¯B. `/metrics`, Prometheus).
* CI/CD (GitHub Actions: Tests + Docker Build + Autoâ€‘Deploy).
* Caching/Batchâ€‘Predict.
* Inputâ€‘Schemaâ€‘Dokumentation mit Beispielen (OpenAPI/Swaggerâ€‘Erweiterungen).

---

## â“ FAQ / Troubleshooting

* **`/predict` liefert 503 (â€žModell nicht geladenâ€œ) â€¦**

  * `model.joblib` existiert? Name/Pfad mit `MODEL_PATH` korrekt? Nicht in `.dockerignore`?
* **`KeyError: 'feature1'`**

  * Spaltennamen beim Training (`train.py`) und beim Request identisch halten.
* **Port/502â€‘Probleme beim Hoster**

  * CMD nutzt `${PORT:-8000}`? Healthâ€‘Pfad `/health` gesetzt?
* **Zu wenig Logs**

  * `LOG_LEVEL=DEBUG` in Env setzen.

---

## ðŸ™Œ Dank & Quellen

* Dieses Projekt orientiert sich an einem praxisnahen â€žProductionâ€‘Grade AIâ€œâ€‘Tutorial (Struktur/Ideen). Code & Struktur sind allgemein gehalten und kÃ¶nnen frei angepasst/erweitert werden.

---

> Pull Requests & Feedback sind willkommen! ðŸ˜Š
